# LLM配置
llm:
  provider: "openai_deepseek"  # 可选的提供商包括: openai，openai_deepseek，openai_siliconflow，openai_kimi，openai_doubao，zhipuai
  max_requests: 10  # 最大请求次数
  default_model_index: 0  # 默认使用第一个模型
  openai:
    api_key: "your-api-key"
    base_url: "https://api.openai.com/v1"  # 可选，用于自定义API端点
    models:
      - "gpt-4-1106-preview"
      - "gpt-4"
      - "gpt-3.5-turbo"
    temperature: 0.7
    max_tokens: 8192
  openai_deepseek:
    api_key: "your-api-key"
    base_url: "https://api.deepseek.com/v1"
    models:
      - "deepseek-chat"
      - "deepseek-coder"
    temperature: 0.7
    max_tokens: 8192
  openai_siliconflow:
    api_key: "your-api-key"
    base_url: "https://api.siliconflow.com/v1"
    models:
      - "Qwen/Qwen2.5-72B-Instruct"
      - "Qwen/Qwen2.5-7B-Instruct"
    temperature: 0.7
    max_tokens: 4096
  openai_kimi:
    api_key: "your-api-key"
    base_url: "https://api.moonshot.cn/v1"
    models:
      - "moonshot-v1-8k"
      - "moonshot-v1-32k"
    temperature: 0.7
    max_tokens: 8192
  openai_aistudio:
    api_key: "your-api-key"
    base_url: "https://api.baidu.com/v1"
    models:
      - "ernie-bot-4"
      - "ernie-bot"
    temperature: 0.7
    max_tokens: 4096
  openai_doubao:
    api_key: "your-api-key"
    base_url: "https://ark.cn-beijing.volces.com/api/v3"
    models:
      - "doubao-v1"
    temperature: 0.7
    max_tokens: 4096
  zhipuai:
    api_key: "your-zhipu-api-key"
    models:
      - "glm-4"
      - "glm-3-turbo"
    temperature: 0.7
    max_tokens: 8192
  ai_studio:
    api_key: "your-api-key"
    base_url: "https://aistudio.baidu.com/llm/lmapi/v3"
    models:
      - "deepseek-r1"
    temperature: 0.7
    max_tokens: 8192
  ai_studio_fast_deploy:
    api_key: "your-api-key"
    base_url: "https://api-f6f9v9xdo8n0j2yd.aistudio-app.com/v1"
    models:
      - "deepseek-r1:32b"
    temperature: 0.7
    max_tokens: 8192

vlm:
  provider: "openai_siliconflow"  # 可选的提供商包括: openai_siliconflow
  openai_siliconflow:
    api_key: "your-api-key"
    base_url: "https://api.siliconflow.com/v1"
    models:
      - "Qwen/Qwen2-VL-72B-Instruct"
      - "Qwen/Qwen2-VL-7B-Instruct"
    temperature: 0.7
    max_tokens: 4096


# 输出配置
output:
  default_format: "markdown"  # 可选: markdown, csv, folder
  base_path: "outputs/"
  markdown_template: "templates/markdown_template.md"
  csv_columns: ["title", "url", "summary", "methodology", "results", "timestamp"]

# 提示词配置
prompts:
  file: "config/prompts_llm.yaml"  # 提示词配置文件路径
  default: "summary"
  available:
    - summary
    - methodology
    - results
    - contribution
    - full_analysis

# Agent配置
agent:
  max_iterations: 5
  timeout: 300  # 秒
  memory_window: 10
